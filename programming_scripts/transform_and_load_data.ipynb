{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transform, Format and Clean Data. \n",
    "\n",
    "# 2. Seperate into dimensions and facts\n",
    "\n",
    "# 3. Save the data frames as CSV  \n",
    "\n",
    "# 4. Load Data into the Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON config file\n",
    "config_file_path = 'config.json'\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "    config = json.load(config_file) \n",
    "\n",
    "# Azure connection string\n",
    "CONNECTION_STRING = config['AZURE_CONNECTION_STRING']\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING)\n",
    "\n",
    "# Database connection\n",
    "DATABASE = config['DW_CONNECTION_STRING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_list(container_name):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_list = container_client.list_blobs()\n",
    "    return blob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_blob_data(container_name, blob):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob.name)\n",
    "    blob_content = blob_client.download_blob().readall()\n",
    "    return blob_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    response = requests.get(url)\n",
    "    return io.BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from Azure Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppp_loan_data():\n",
    "    container_name = 'pppdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "    \n",
    "    for blob in blob_list:\n",
    "        if \"public_150k_plus\" in blob.name:\n",
    "            print(f\"Downloading {blob.name}\")\n",
    "            blob_data = get_azure_blob_data(container_name, blob)\n",
    "            print(f\"Downloaded {blob.name} successfully\")\n",
    "            data = io.BytesIO(blob_data)\n",
    "            print(f\"Reading {blob.name}\")\n",
    "            df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\n",
    "            df = pd.concat(df_chunks)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naics_data():\n",
    "    container_name = 'naicsdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdp_data():\n",
    "    container_name = 'gdpdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating, and Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_naics_data():\n",
    "    df_naics = get_naics_data()\n",
    "    df_naics.rename(columns={\n",
    "        'Code': 'NAICS_CODE',\n",
    "        'Title': 'NAICS_TITLE',\n",
    "        'Description': 'DESCRIPTION'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return df_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_gdp_data():\n",
    "    df_gdp  = get_gdp_data()\n",
    "\n",
    "    # Pivot the data in GDP data\n",
    "    selected_columns = ['GeoFIPS', 'GeoName', 'Region', 'Description', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "    df_gdp = df_gdp[selected_columns]\n",
    "    pivot_data = df_gdp.melt(id_vars=[\"GeoFIPS\", \"GeoName\", \"Region\", \"Description\"],\n",
    "                                    value_vars=[\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"],\n",
    "                                    var_name=\"date_id\",\n",
    "                                    value_name=\"Value\")\n",
    "    pivot_data = pivot_data.pivot_table(index=[\"GeoFIPS\", \"GeoName\", \"Region\", \"date_id\"], columns=\"Description\", values=\"Value\", aggfunc='first').reset_index()\n",
    "    pivot_data = pivot_data.sort_values(by=[\"GeoFIPS\", \"date_id\"])\n",
    "    pivot_data.rename(columns={\n",
    "        \"Chain-type quantity indexes for real GDP \": \"CHAIN_TYPE_QUANTITY_INDEX\",\n",
    "        \"Current-dollar GDP (thousands of current dollars) \": \"CURRENT_DOLLAR_GDP\",\n",
    "        \"Real GDP (thousands of chained 2017 dollars) \": \"REAL_GDP\",\n",
    "        \"GeoFIPS\": \"GEOFIPS\",\n",
    "        \"GeoName\": \"GEO_NAME\",\n",
    "        \"Description\": \"Index\",\n",
    "        \"date_id\": \"YEAR_ID\"\n",
    "    }, inplace=True)\n",
    "    pivot_data['FACTS_GDP_ID'] = range(1, len(pivot_data) + 1)\n",
    "    final_data = pivot_data.drop(columns='Description', errors='ignore')\n",
    "    final_data = pivot_data[['FACTS_GDP_ID', 'GEOFIPS', 'GEO_NAME', 'Region', 'YEAR_ID', 'CHAIN_TYPE_QUANTITY_INDEX',\n",
    "                         'CURRENT_DOLLAR_GDP', 'REAL_GDP']]\n",
    "    df_gdp = final_data\n",
    "\n",
    "    # Remove the quation marks from GEOFIPS\n",
    "    df_gdp['GEOFIPS'] = df_gdp['GEOFIPS'].str.replace('\"', '')\n",
    "\n",
    "    return df_gdp\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ppp_loan_data():\n",
    "    df_ppp = get_ppp_loan_data()\n",
    "    # Drop the columns that are not required\n",
    "    df_ppp.drop(columns=[\n",
    "        'UTILITIES_PROCEED',\n",
    "        'PAYROLL_PROCEED',\n",
    "        'MORTGAGE_INTEREST_PROCEED',\n",
    "        'RENT_PROCEED',\n",
    "        'REFINANCE_EIDL_PROCEED',\n",
    "        'HEALTH_CARE_PROCEED',\n",
    "        'DEBT_INTEREST_PROCEED',\n",
    "        'RuralUrbanIndicator',\n",
    "        'HubzoneIndicator',\n",
    "        'LMIIndicator',\n",
    "        'ProjectCity',\n",
    "        'ProjectZip',\n",
    "        'CD'\n",
    "    ], inplace=True)\n",
    "    # Rename the columns to match the SQL table\n",
    "    df_ppp.rename(columns={\n",
    "        'LoanNumber': 'LOAN_NUMBER',\n",
    "        'DateApproved': 'DATE_APPROVED_ID',\n",
    "        'SBAOfficeCode': 'SBA_OFFICE_CODE',\n",
    "        'ProcessingMethod': 'PROCESSING_METHOD',\n",
    "        'BorrowerName': 'BORROWER_NAME',\n",
    "        'BorrowerAddress': 'BORROWER_ADDRESS',\n",
    "        'BorrowerCity': 'BORROWER_CITY',\n",
    "        'BorrowerState': 'BORROWER_STATE',\n",
    "        'BorrowerZip': 'BORROWER_ZIP',\n",
    "        'LoanStatusDate': 'LOAN_STATUS_DATE_ID',\n",
    "        'LoanStatus': 'LOAN_STATUS',\n",
    "        'Term': 'TERM_MONTH',\n",
    "        'SBAGuarantyPercentage': 'SBA_GUARANTY_PERCENTAGE',\n",
    "        'InitialApprovalAmount': 'INITIAL_APPROVAL_AMOUNT',\n",
    "        'CurrentApprovalAmount': 'CURRENT_APPROVAL_AMOUNT',\n",
    "        'UndisbursedAmount': 'UNDISBURSED_AMOUNT',\n",
    "        'FranchiseName': 'FRANCHISE_NAME',\n",
    "        'ServicingLenderLocationID': 'SERVICING_LENDER_LOCATION_ID',\n",
    "        'ServicingLenderName': 'SERVICING_LENDER_NAME',\n",
    "        'ServicingLenderAddress': 'SERVICING_LENDER_ADDRESS',\n",
    "        'ServicingLenderCity': 'SERVICING_LENDER_CITY',\n",
    "        'ServicingLenderState': 'SERVICING_LENDER_STATE',\n",
    "        'ServicingLenderZip': 'SERVICING_LENDER_ZIP',\n",
    "        'BusinessAgeDescription': 'BUSINESS_AGE_DESCRIPTION',\n",
    "        'ProjectCity': 'PROJECT_CITY',\n",
    "        'ProjectCountyName': 'PROJECT_COUNTY_NAME',\n",
    "        'Race': 'RACE',\n",
    "        'Ethnicity': 'ETHNICITY',\n",
    "        'Gender': 'GENDER',\n",
    "        'BusinessType': 'BUSINESS_TYPE',\n",
    "        'OriginatingLenderLocationID': 'ORIGINATING_LENDER_LOCATION_ID',\n",
    "        'OriginatingLender': 'ORIGINATING_LENDER',\n",
    "        'OriginatingLenderCity': 'ORIGINATING_LENDER_CITY',\n",
    "        'OriginatingLenderState': 'ORIGINATING_LENDER_STATE',\n",
    "        'Veteran': 'VETERAN',\n",
    "        'NonProfit': 'NONPROFIT',\n",
    "        'ForgivenessAmount': 'FORGIVENESS_AMOUNT',\n",
    "        'ForgivenessDate': 'FORGIVENESS_DATE_ID',\n",
    "        'JobsReported': 'JOBS_REPORTED',\n",
    "        'NAICSCode': 'NAICS_CODE'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Change the PPP Date columns to match SQL format\n",
    "    date_columns = ['DATE_APPROVED_ID', 'FORGIVENESS_DATE_ID', 'LOAN_STATUS_DATE_ID']\n",
    "    for col in date_columns:\n",
    "        df_ppp[col] = pd.to_datetime(df_ppp[col], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Drop all the rows where Borrower State is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['BORROWER_STATE'])\n",
    "\n",
    "    # Change NonProfit to boolean\n",
    "    df_ppp['NONPROFIT'] = df_ppp['NONPROFIT'].map({'Y': True})\n",
    "\n",
    "    # Change Veteran to boolean\n",
    "    df_ppp['VETERAN'] = df_ppp['VETERAN'].map({'Veteran': True, 'Non-Veteran': False, 'Unanswered':None})\n",
    "\n",
    "    # Sentence case Borrower Address and City and Orginating Lender City\n",
    "    df_ppp['BORROWER_ADDRESS'] = df_ppp['BORROWER_ADDRESS'].str.title()\n",
    "    df_ppp['BORROWER_CITY'] = df_ppp['BORROWER_CITY'].str.title()\n",
    "    df_ppp['ORIGINATING_LENDER_CITY'] = df_ppp['ORIGINATING_LENDER_CITY'].str.title()\n",
    "    \n",
    "    return df_ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = reformat_ppp_loan_data()\n",
    "#Show all the types of each column\n",
    "print(ppp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Schema\n",
    "DIM_BORROWER\n",
    "\n",
    "BORROWER_ID (integer, primary key)\n",
    "BORROWER_NAME (varchar(200))\n",
    "BORROWER_ADDRESS (varchar(200))\n",
    "BORROWER_CITY (varchar(100))\n",
    "BORROWER_STATE (varchar(100))\n",
    "BORROWER_ZIP (varchar(100))\n",
    "RACE (varchar(100))\n",
    "ETHNICITY (varchar(100))\n",
    "GENDER (varchar(100))\n",
    "VETERAN (boolean)\n",
    "FRANCHISE_NAME (varchar(200))\n",
    "NONPROFIT (boolean)\n",
    "JOBS_REPORTED (integer)\n",
    "\n",
    "DIM_BUSINESS_AGE\n",
    "\n",
    "BUSINESS_AGE_ID (integer, primary key)\n",
    "BUSINESS_AGE_DESCRIPTION (varchar(200))\n",
    "\n",
    "DIM_BUSINESS_TYPE\n",
    "\n",
    "BUSINESS_TYPE_ID (integer, primary key)\n",
    "BUSINESS_TYPE (varchar(200))\n",
    "\n",
    "DIM_DATE\n",
    "\n",
    "DATE_ID (integer, primary key)\n",
    "YEAR_NUMBER (integer)\n",
    "MONTH_NUMBER (integer)\n",
    "QUARTER_NUMBER (integer)\n",
    "DAY_NUMBER (integer)\n",
    "HOUR_NUMBER (integer)\n",
    "ISHOLIDAY (boolean)\n",
    "DAY_NAME (varchar(100))\n",
    "MONTH_NAME (varchar(100))\n",
    "WEEK_OF_MONTH (integer)\n",
    "WEEK_OF_YEAR (integer)\n",
    "\n",
    "DIM_GEOGRAPHY\n",
    "\n",
    "GEOFIPS (integer, primary key)\n",
    "GEO_NAME (varchar(100))\n",
    "REGION (varchar(50))\n",
    "PROJECT_COUNTY_NAME (varchar(200))\n",
    "PROJECT_STATE (varchar(100))\n",
    "\n",
    "DIM_LOAN_STATUS\n",
    "\n",
    "LOAN_STATUS_ID (integer, primary key)\n",
    "LOAN_STATUS (varchar(100))\n",
    "\n",
    "DIM_NAICS\n",
    "\n",
    "NAICS_CODE (integer, primary key)\n",
    "NAICS_TITLE (varchar(200))\n",
    "DESCRIPTION (text)\n",
    "\n",
    "DIM_ORIGINATING_LENDER\n",
    "\n",
    "ORIGINATING_LENDER_ID (integer, primary key)\n",
    "ORIGINATING_LENDER_LOCATION_ID (integer)\n",
    "ORIGINATING_LENDER (varchar(200))\n",
    "ORIGINATING_LENDER_CITY (varchar(200))\n",
    "ORIGINATING_LENDER_STATE (varchar(100))\n",
    "\n",
    "DIM_PROCESSING_METHOD\n",
    "\n",
    "PROCESSING_METHOD_ID (integer, primary key)\n",
    "PROCESSING_METHOD (varchar(100))\n",
    "\n",
    "DIM_SBA_OFFICE\n",
    "\n",
    "SBA_OFFICE_CODE (integer, primary key)\n",
    "\n",
    "DIM_SERVICING_LENDER\n",
    "\n",
    "SERVICING_LENDER_ID (integer, primary key)\n",
    "SERVICING_LENDER_LOCATION_ID (integer)\n",
    "SERVICING_LENDER_NAME (varchar(200))\n",
    "SERVICING_LENDER_ADDRESS (varchar(200))\n",
    "SERVICING_LENDER_CITY (varchar(100))\n",
    "SERVICING_LENDER_STATE (varchar(200))\n",
    "SERVICING_LENDER_ZIP (integer)\n",
    "\n",
    "DIM_TERM\n",
    "\n",
    "TERM_ID (integer, primary key)\n",
    "TERM_MONTH (integer)\n",
    "\n",
    "FACTS_GDP\n",
    "\n",
    "FACTS_GDP_ID (integer, primary key)\n",
    "YEAR_ID (integer, foreign key)\n",
    "REAL_GDP (number)\n",
    "CHAIN_TYPE_INDEX_GDP (number)\n",
    "CURRENT_DOLLAR_GDP (number)\n",
    "GEOFIPS (integer, foreign key)\n",
    "\n",
    "FACTS_PPP\n",
    "\n",
    "FACTS_PPP_ID (integer, primary key)\n",
    "LOAN_NUMBER (integer)\n",
    "NAICS_CODE (integer, foreign key)\n",
    "GEOFIPS (integer, foreign key)\n",
    "DATE_APPROVED_ID (integer, foreign key)\n",
    "LOAN_STATUS_DATE_ID (integer, foreign key)\n",
    "FORGIVENESS_DATE_ID (integer, foreign key)\n",
    "BORROWER_ID (integer, foreign key)\n",
    "ORIGINATING_LENDER_ID (integer, foreign key)\n",
    "SERVICING_LENDER_ID (integer, foreign key)\n",
    "TERM_ID (integer, foreign key)\n",
    "LOAN_STATUS_ID (integer, foreign key)\n",
    "PROCESSING_METHOD_ID (integer, foreign key)\n",
    "SBA_OFFICE_CODE (integer, foreign key)\n",
    "BUSINESS_AGE_ID (integer, foreign key)\n",
    "BUSINESS_TYPE_ID (integer, foreign key)\n",
    "SBA_GUARANTY_PERCENTAGE (number)\n",
    "INITIAL_APPROVAL_AMOUNT (number)\n",
    "CURRENT_APPROVAL_AMOUNT (number)\n",
    "UNDISBURSED_AMOUNT (number)\n",
    "FORGIVENESS_AMOUNT (number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Dimensions and Facts Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading public_150k_plus_230930.csv\n",
      "Downloaded public_150k_plus_230930.csv successfully\n",
      "Reading public_150k_plus_230930.csv\n"
     ]
    }
   ],
   "source": [
    "clean_ppp_data = reformat_ppp_loan_data()\n",
    "clean_naics_data = reformat_naics_data()\n",
    "clean_gdp_data = reformat_gdp_data()\n",
    "\n",
    "\n",
    "# Create the dimensions\n",
    "dim_naics = reformat_naics_data() # Completed\n",
    "dim_sba_office = clean_ppp_data[['SBA_OFFICE_CODE']] # Completed\n",
    "\n",
    "dim_geography = pd.DataFrame(columns=['GEOFIPS', 'GEONAME', 'PROJECT_COUNTY_NAME', 'PROJECT_STATE'])\n",
    "dim_date = pd.DataFrame(columns=['DATE_ID'])\n",
    "dim_originating_lender = pd.DataFrame(columns=['ORIGINATING_LENDER_ID'])\n",
    "dim_borrower = pd.DataFrame(columns=['BORROWER_ID'])\n",
    "dim_servicing_lender = pd.DataFrame(columns=['SERVICING_LENDER_ID'])\n",
    "\n",
    "# These tables will need to be built with .factorize() method\n",
    "dim_loan_status = pd.DataFrame(columns=['LOAN_STATUS_ID'])\n",
    "dim_business_type = pd.DataFrame(columns=['BUSINESS_TYPE_ID'])\n",
    "dim_processing_method = pd.DataFrame(columns=['PROCESSING_METHOD_ID'])\n",
    "dim_term = pd.DataFrame(columns=['TERM_ID'])\n",
    "dim_business_age = pd.DataFrame(columns=['BUSINESS_AGE_ID'])\n",
    "\n",
    "# Create the fact table\n",
    "facts_ppp_loan = pd.DataFrame(columns=['FACTS_PPP_ID'])\n",
    "facts_gdp = pd.DataFrame(columns=['FACTS_GDP_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_of_month(dt):\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "    week_number = (day - 1) // 7 + 1\n",
    "    return week_number\n",
    "\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date = pd.to_datetime('2024-03-31')\n",
    "# Create a DataFrame for the date dimension\n",
    "date_dimension = pd.DataFrame({'date': pd.date_range(start_date, end_date, freq='H')})\n",
    "\n",
    "date_dimension.head(25)\n",
    "\n",
    "# Extract attributes\n",
    "date_dimension['year_number'] = date_dimension['date'].dt.year\n",
    "date_dimension['quarter_number'] = date_dimension['date'].dt.quarter\n",
    "date_dimension['month_number'] = date_dimension['date'].dt.month\n",
    "date_dimension['monthName'] = date_dimension['date'].dt.strftime('%B')\n",
    "date_dimension['daynumber'] = date_dimension['date'].dt.day\n",
    "date_dimension['dayName'] = date_dimension['date'].dt.strftime('%A')\n",
    "date_dimension['hour_number'] = date_dimension['date'].dt.hour\n",
    "date_dimension['date_iso_format'] = date_dimension['date'].apply(lambda x: x.isoformat())\n",
    "date_dimension['date_id'] = date_dimension['date'].dt.strftime('%Y%m%d%H')\n",
    "\n",
    "# Add week of the month and week of the year\n",
    "date_dimension['weekofMonth'] = date_dimension['date'].apply(week_of_month)\n",
    "date_dimension['weekofYear'] = date_dimension['date'].dt.strftime('%U')\n",
    "\n",
    "new_order = ['date_id', 'date_iso_format','year_number','quarter_number','month_number','daynumber','hour_number','monthName','dayName','weekofYear','weekofMonth']\n",
    "date_dimension = date_dimension[new_order]\n",
    "\n",
    "date_dimension.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer originating lender data to dim_originating_lender\n",
    "dim_originating_lender = clean_ppp_data[['ORIGINATING_LENDER_LOCATION_ID', 'ORIGINATING_LENDER', 'ORIGINATING_LENDER_CITY', 'ORIGINATING_LENDER_STATE']]\n",
    "\n",
    "\n",
    "dim_borrower = clean_ppp_data[['BORROWER_NAME', 'BORROWER_ADDRESS', 'BORROWER_CITY', 'BORROWER_STATE', 'BORROWER_ZIP', 'RACE', 'ETHNICITY', 'FRANCHISE_NAME', 'GENDER', 'VETERAN', 'NONPROFIT', 'JOBS_REPORTED']]\n",
    "\n",
    "# Transfer servicing lender data to dim_servicing_lender\n",
    "dim_servicing_lender = clean_ppp_data[['SERVICING_LENDER_LOCATION_ID', 'SERVICING_LENDER_NAME', 'SERVICING_LENDER_ADDRESS', 'SERVICING_LENDER_CITY', 'SERVICING_LENDER_STATE', 'SERVICING_LENDER_ZIP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data frames as CSV  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into the Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
