{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transform, Format and Clean Data. \n",
    "\n",
    "# 2. Seperate into dimensions and facts\n",
    "\n",
    "# 3. Save the data into the warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON config file\n",
    "config_file_path = 'config.json'\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "    config = json.load(config_file) \n",
    "\n",
    "# Azure connection string\n",
    "CONNECTION_STRING = config['AZURE_CONNECTION_STRING']\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING)\n",
    "\n",
    "# Database connection\n",
    "DATABASE = config['DW_CONNECTION_STRING']\n",
    "engine = create_engine(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_list(container_name):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_list = container_client.list_blobs()\n",
    "    return blob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_blob_data(container_name, blob):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob.name)\n",
    "    stream = blob_client.download_blob()\n",
    "    blob_content = b\"\"\n",
    "    for chunk in stream.chunks():\n",
    "        blob_content += chunk\n",
    "    return blob_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    response = requests.get(url)\n",
    "    return io.BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving the data from Azure Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppp_loan_data():\n",
    "    container_name = 'pppdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "    df_list = []  # Initialize df_list outside the loop\n",
    "\n",
    "    print(f\"Downloading data from {container_name} container\\n\")\n",
    "    for blob in blob_list:\n",
    "        print(f\"Downloading:\\t{blob.name}\")\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        print(f\"Downloaded {blob.name} successfully\\n\")\n",
    "        data = io.BytesIO(blob_data)\n",
    "        print(f\"Reading:\\t{blob.name}\")\n",
    "        df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\n",
    "        for chunk in df_chunks:\n",
    "            df_list.append(chunk)\n",
    "        print(f\"Read {blob.name} successfully\\n\\n\")\n",
    "    \n",
    "    if df_list:  # Check if df_list is not empty\n",
    "        df = pd.concat(df_list)\n",
    "        print(f\"PPP consolidated successfully\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data downloaded.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_ppp_loan_data():\\n    container_name = \\'pppdata\\'\\n    blob_list = get_blob_list(container_name)\\n    \\n    for blob in blob_list:\\n        if \"public_150k_plus\" in blob.name:\\n            print(f\"Downloading {blob.name}\")\\n            blob_data = get_azure_blob_data(container_name, blob)\\n            print(f\"Downloaded {blob.name} successfully\")\\n            data = io.BytesIO(blob_data)\\n            print(f\"Reading {blob.name}\")\\n            df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\\n            df_list = []\\n            for chunk in df_chunks:\\n                df_list.append(chunk)\\n            df = pd.concat(df_list)\\n            return df'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing only one file\n",
    "\"\"\"def get_ppp_loan_data():\n",
    "    container_name = 'pppdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "    \n",
    "    for blob in blob_list:\n",
    "        if \"public_150k_plus\" in blob.name:\n",
    "            print(f\"Downloading {blob.name}\")\n",
    "            blob_data = get_azure_blob_data(container_name, blob)\n",
    "            print(f\"Downloaded {blob.name} successfully\")\n",
    "            data = io.BytesIO(blob_data)\n",
    "            print(f\"Reading {blob.name}\")\n",
    "            df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\n",
    "            df_list = []\n",
    "            for chunk in df_chunks:\n",
    "                df_list.append(chunk)\n",
    "            df = pd.concat(df_list)\n",
    "            return df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naics_data():\n",
    "    container_name = 'naicsdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdp_data():\n",
    "    container_name = 'gdpdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating, and Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_naics_data():\n",
    "    df_naics = get_naics_data()\n",
    "    df_naics.rename(columns={\n",
    "        'Code': 'naics_code',\n",
    "        'Title': 'naics_title',\n",
    "        'Description': 'description'\n",
    "    }, inplace=True)\n",
    "    # Remove all the rows where naics_code is not a number\n",
    "    # The naics_code column has some generic values like \"31-33\" which are not valid NAICS codes\n",
    "    df_naics = df_naics[df_naics['naics_code'].str.isnumeric()]\n",
    "\n",
    "    df_naics['naics_code'] = df_naics['naics_code'].astype(int)\n",
    "    df_naics['naics_title'] = df_naics['naics_title'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_naics['description'] = df_naics['description'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    \n",
    "    return df_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_gdp_data():\n",
    "    df_gdp  = get_gdp_data()\n",
    "    #Drop all the records where 2017, 2018, 2019, 2020, 2021, 2022 = \"(NA)\" \n",
    "    df_gdp = df_gdp[df_gdp['2017'] != \"(NA)\"]\n",
    "    df_gdp = df_gdp[df_gdp['2020'] != \"(NA)\"]\n",
    "\n",
    "    # Pivot the data in GDP data\n",
    "    selected_columns = ['GeoFIPS', 'GeoName', 'Region', 'Description', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "    df_gdp = df_gdp[selected_columns]\n",
    "    pivot_data = df_gdp.melt(id_vars=[\"GeoFIPS\", \"GeoName\", \"Region\", \"Description\"],\n",
    "                                    value_vars=[\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"],\n",
    "                                    var_name=\"date_id\",\n",
    "                                    value_name=\"Value\")\n",
    "    pivot_data = pivot_data.pivot_table(index=[\"GeoFIPS\", \"GeoName\", \"Region\", \"date_id\"], columns=\"Description\", values=\"Value\", aggfunc='first').reset_index()\n",
    "    pivot_data = pivot_data.sort_values(by=[\"GeoFIPS\", \"date_id\"])\n",
    "    pivot_data.rename(columns={\n",
    "        \"Chain-type quantity indexes for real GDP \": \"chain_type_index_gdp\",\n",
    "        \"Current-dollar GDP (thousands of current dollars) \": \"current_dollar_gdp\",\n",
    "        \"Real GDP (thousands of chained 2017 dollars) \": \"real_gdp\",\n",
    "        \"GeoFIPS\": \"geofips\",\n",
    "        \"GeoName\": \"geo_name\",\n",
    "        \"Description\": \"Index\",\n",
    "        \"date_id\": \"year_id\",\n",
    "        \"Region\": \"region\"\n",
    "    }, inplace=True)\n",
    "    pivot_data['facts_gdp_id'] = range(1, len(pivot_data) + 1)\n",
    "    final_data = pivot_data.drop(columns='Description', errors='ignore')\n",
    "    final_data = pivot_data[['facts_gdp_id', 'geofips', 'geo_name', 'region', 'year_id', 'chain_type_index_gdp',\n",
    "                         'current_dollar_gdp', 'real_gdp']]\n",
    "    df_gdp = final_data\n",
    "\n",
    "    # Remove the quation marks from geofips\n",
    "    df_gdp['geofips'] = df_gdp['geofips'].str.replace('\"', '')\n",
    "    \n",
    "    # Change the YearID to match the format in the Date Dimension\n",
    "    df_gdp['year_id'] = pd.to_datetime(df_gdp['year_id'], format='%Y').dt.strftime('%Y%m%d%H')\n",
    "    \n",
    "    # Change the data types of the columns\n",
    "    df_gdp['year_id'] = df_gdp['year_id'].astype(int)\n",
    "    df_gdp['geofips'] = df_gdp['geofips'].astype(int)\n",
    "    df_gdp['geo_name'] = df_gdp['geo_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_gdp['region'] = df_gdp['region'].astype(pd.StringDtype(\"pyarrow\"))    \n",
    "    df_gdp['chain_type_index_gdp'] = df_gdp['chain_type_index_gdp'].astype(float)\n",
    "    df_gdp['current_dollar_gdp'] = df_gdp['current_dollar_gdp'].astype(float)\n",
    "    df_gdp['real_gdp'] = df_gdp['real_gdp'].astype(float)\n",
    "\n",
    "\n",
    "    return df_gdp\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ppp_loan_data():\n",
    "    df_ppp = get_ppp_loan_data()\n",
    "\n",
    "\n",
    "    # Delete the columns that are not required\n",
    "    df_ppp.drop(columns=[\n",
    "        'UTILITIES_PROCEED',\n",
    "        'PAYROLL_PROCEED',\n",
    "        'MORTGAGE_INTEREST_PROCEED',\n",
    "        'RENT_PROCEED',\n",
    "        'REFINANCE_EIDL_PROCEED',\n",
    "        'HEALTH_CARE_PROCEED',\n",
    "        'DEBT_INTEREST_PROCEED',\n",
    "        'RuralUrbanIndicator',\n",
    "        'HubzoneIndicator',\n",
    "        'LMIIndicator',\n",
    "        'ProjectCity',\n",
    "        'ProjectZip',\n",
    "        'CD'\n",
    "    ], inplace=True)\n",
    "    # Rename the columns to match the SQL table\n",
    "    df_ppp.rename(columns={\n",
    "        'LoanNumber': 'loan_number',\n",
    "        'DateApproved': 'date_approved_id',\n",
    "        'SBAOfficeCode': 'sba_office_code',\n",
    "        'ProcessingMethod': 'processing_method',\n",
    "        'BorrowerName': 'borrower_name',\n",
    "        'BorrowerAddress': 'borrower_address',\n",
    "        'BorrowerCity': 'borrower_city',\n",
    "        'BorrowerState': 'borrower_state',\n",
    "        'BorrowerZip': 'borrower_zip',\n",
    "        'LoanStatusDate': 'loan_status_date_id',\n",
    "        'LoanStatus': 'loan_status',\n",
    "        'Term': 'term_month',\n",
    "        'SBAGuarantyPercentage': 'sba_guaranty_percentage',\n",
    "        'InitialApprovalAmount': 'initial_approval_amount',\n",
    "        'CurrentApprovalAmount': 'current_approval_amount',\n",
    "        'UndisbursedAmount': 'undisbursed_amount',\n",
    "        'FranchiseName': 'franchise_name',\n",
    "        'ServicingLenderLocationID': 'servicing_lender_location_id',\n",
    "        'ServicingLenderName': 'servicing_lender_name',\n",
    "        'ServicingLenderAddress': 'servicing_lender_address',\n",
    "        'ServicingLenderCity': 'servicing_lender_city',\n",
    "        'ServicingLenderState': 'servicing_lender_state',\n",
    "        'ServicingLenderZip': 'servicing_lender_zip',\n",
    "        'BusinessAgeDescription': 'business_age_description',\n",
    "        'ProjectState': 'project_state',\n",
    "        'ProjectCountyName': 'project_county_name',\n",
    "        'Race': 'race',\n",
    "        'Ethnicity': 'ethnicity',\n",
    "        'Gender': 'gender',\n",
    "        'BusinessType': 'business_type',\n",
    "        'OriginatingLenderLocationID': 'originating_lender_location_id',\n",
    "        'OriginatingLender': 'originating_lender',\n",
    "        'OriginatingLenderCity': 'originating_lender_city',\n",
    "        'OriginatingLenderState': 'originating_lender_state',\n",
    "        'Veteran': 'veteran',\n",
    "        'NonProfit': 'nonprofit',\n",
    "        'ForgivenessAmount': 'forgiveness_amount',\n",
    "        'ForgivenessDate': 'forgiveness_date_id',\n",
    "        'JobsReported': 'jobs_reported',\n",
    "        'NAICSCode': 'naics_code'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Droping all the empty rows\n",
    "    # Drop all the rows where Borrower State is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['borrower_state'])\n",
    "\n",
    "    # Drop all the rows where naics_code is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['naics_code'])\n",
    "\n",
    "    # Drop all the rows where dates are empty\n",
    "    df_ppp = df_ppp.dropna(subset=['date_approved_id', 'loan_status_date_id', 'forgiveness_date_id'])\n",
    "\n",
    "    # Drop all the rows where jobs reported is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['jobs_reported'])\n",
    "\n",
    "    # Drop all the rows where business type is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['business_type'])\n",
    "\n",
    "    # Drop all the rows where business age description is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['business_age_description'])\n",
    "    # or where the value is Unanswered\n",
    "    df_ppp = df_ppp[df_ppp['business_age_description'] != 'Unanswered']\n",
    "\n",
    "    \n",
    "\n",
    "    # Change the Date columns to match the format in the Date Dimension\n",
    "    df_ppp['forgiveness_date_id'] = pd.to_datetime(df_ppp['forgiveness_date_id']).dt.strftime('%Y%m%d%H')\n",
    "    df_ppp['date_approved_id'] = pd.to_datetime(df_ppp['date_approved_id']).dt.strftime('%Y%m%d%H')\n",
    "    df_ppp['loan_status_date_id'] = pd.to_datetime(df_ppp['loan_status_date_id']).dt.strftime('%Y%m%d%H')\n",
    "    \n",
    "    # Change nonprofit to boolean\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].map({'Y': True})\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].fillna(False)\n",
    "\n",
    "    # Change veteran to boolean\n",
    "    df_ppp['veteran'] = df_ppp['veteran'].map({'veteran': True, 'Non-veteran': False, 'Unanswered':None})\n",
    "\n",
    "    # Sentence case the string columns\n",
    "    df_ppp['borrower_address'] = df_ppp['borrower_address'].str.title()\n",
    "    df_ppp['borrower_city'] = df_ppp['borrower_city'].str.title()\n",
    "    df_ppp['originating_lender_city'] = df_ppp['originating_lender_city'].str.title()\n",
    "    df_ppp['servicing_lender_city'] = df_ppp['servicing_lender_city'].str.title()\n",
    "    df_ppp['project_county_name'] = df_ppp['project_county_name'].str.title()\n",
    "    \n",
    "    #df_ppp['loan_number'] = df_ppp['loan_number'].astype(int)\n",
    "    df_ppp['date_approved_id'] = df_ppp['date_approved_id'].astype(int)\n",
    "    df_ppp['sba_office_code'] = df_ppp['sba_office_code'].astype(int)\n",
    "    df_ppp['processing_method'] = df_ppp['processing_method'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_name'] = df_ppp['borrower_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_address'] = df_ppp['borrower_address'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_city'] = df_ppp['borrower_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_state'] = df_ppp['borrower_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_zip'] = df_ppp['borrower_zip'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['loan_status_date_id'] = df_ppp['loan_status_date_id'].astype(int)\n",
    "    df_ppp['loan_status'] = df_ppp['loan_status'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['term_month'] = df_ppp['term_month'].astype(int)\n",
    "    df_ppp['sba_guaranty_percentage'] = df_ppp['sba_guaranty_percentage'].astype(float)\n",
    "    df_ppp['initial_approval_amount'] = df_ppp['initial_approval_amount'].astype(float)\n",
    "    df_ppp['current_approval_amount'] = df_ppp['current_approval_amount'].astype(float)\n",
    "    df_ppp['undisbursed_amount'] = df_ppp['undisbursed_amount'].astype(float)\n",
    "    df_ppp['franchise_name'] = df_ppp['franchise_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_location_id'] = df_ppp['servicing_lender_location_id'].astype(int)\n",
    "    df_ppp['servicing_lender_name'] = df_ppp['servicing_lender_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_address'] = df_ppp['servicing_lender_address'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_city'] = df_ppp['servicing_lender_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_state'] = df_ppp['servicing_lender_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_zip'] = df_ppp['servicing_lender_zip'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['business_age_description'] = df_ppp['business_age_description'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['project_state'] = df_ppp['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['project_county_name'] = df_ppp['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['race'] = df_ppp['race'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['ethnicity'] = df_ppp['ethnicity'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['gender'] = df_ppp['gender'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['business_type'] = df_ppp['business_type'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_location_id'] = df_ppp['originating_lender_location_id'].astype(int)\n",
    "    df_ppp['originating_lender'] = df_ppp['originating_lender'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_city'] = df_ppp['originating_lender_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_state'] = df_ppp['originating_lender_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['veteran'] = df_ppp['veteran'].astype(bool)\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].astype(bool)\n",
    "    df_ppp['forgiveness_amount'] = df_ppp['forgiveness_amount'].astype(float)\n",
    "    df_ppp['forgiveness_date_id'] = df_ppp['forgiveness_date_id'].astype(int)\n",
    "    df_ppp['jobs_reported'] = df_ppp['jobs_reported'].astype(int)\n",
    "    df_ppp['naics_code'] = df_ppp['naics_code'].astype(int)\n",
    "\n",
    "    # Create a FACTS_PPP_ID \n",
    "    df_ppp['facts_ppp_id'] = range(1, len(df_ppp) + 1)\n",
    "\n",
    "    return df_ppp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Dimensions and Facts Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from pppdata container\n",
      "\n",
      "Downloading:\tpublic_150k_plus_230930.csv\n",
      "Downloaded public_150k_plus_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_150k_plus_230930.csv\n",
      "Read public_150k_plus_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_10_230930.csv\n",
      "Downloaded public_up_to_150k_10_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_10_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_10_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_11_230930.csv\n",
      "Downloaded public_up_to_150k_11_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_11_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_11_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_12_230930.csv\n",
      "Downloaded public_up_to_150k_12_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_12_230930.csv\n",
      "Read public_up_to_150k_12_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_1_230930.csv\n",
      "Downloaded public_up_to_150k_1_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_1_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_1_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_2_230930.csv\n",
      "Downloaded public_up_to_150k_2_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_2_230930.csv\n",
      "Read public_up_to_150k_2_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_3_230930.csv\n",
      "Downloaded public_up_to_150k_3_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_3_230930.csv\n",
      "Read public_up_to_150k_3_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_4_230930.csv\n",
      "Downloaded public_up_to_150k_4_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_4_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_4_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_5_230930.csv\n",
      "Downloaded public_up_to_150k_5_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_5_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_5_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_6_230930.csv\n",
      "Downloaded public_up_to_150k_6_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_6_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_6_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_7_230930.csv\n",
      "Downloaded public_up_to_150k_7_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_7_230930.csv\n",
      "Read public_up_to_150k_7_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_8_230930.csv\n",
      "Downloaded public_up_to_150k_8_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_8_230930.csv\n",
      "Read public_up_to_150k_8_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_9_230930.csv\n",
      "Downloaded public_up_to_150k_9_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_9_230930.csv\n",
      "Read public_up_to_150k_9_230930.csv successfully\n",
      "\n",
      "\n",
      "PPP consolidated successfully\n"
     ]
    }
   ],
   "source": [
    "clean_ppp_data = reformat_ppp_loan_data()\n",
    "clean_naics_data = reformat_naics_data()\n",
    "clean_gdp_data = reformat_gdp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics_code</th>\n",
       "      <th>naics_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>The Sector as a Whole\n",
       "\n",
       "The Agriculture, Forest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>Crop Production</td>\n",
       "      <td>Industries in the Crop Production subsector gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111</td>\n",
       "      <td>Oilseed and Grain Farming</td>\n",
       "      <td>This industry group comprises establishments p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11111</td>\n",
       "      <td>Soybean Farming</td>\n",
       "      <td>See industry description for 111110.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111110</td>\n",
       "      <td>Soybean Farming</td>\n",
       "      <td>This industry comprises establishments primari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naics_code                                 naics_title  \\\n",
       "0          11  Agriculture, Forestry, Fishing and Hunting   \n",
       "1         111                             Crop Production   \n",
       "2        1111                   Oilseed and Grain Farming   \n",
       "3       11111                             Soybean Farming   \n",
       "4      111110                             Soybean Farming   \n",
       "\n",
       "                                         description  \n",
       "0  The Sector as a Whole\n",
       "\n",
       "The Agriculture, Forest...  \n",
       "1  Industries in the Crop Production subsector gr...  \n",
       "2  This industry group comprises establishments p...  \n",
       "3               See industry description for 111110.  \n",
       "4  This industry comprises establishments primari...  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dimensions\n",
    "dim_naics = reformat_naics_data() # Completed\n",
    "# Remove T from naics_title\n",
    "dim_naics['naics_title'] = dim_naics['naics_title'].str.replace('T', '')\n",
    "# Reset the index\n",
    "dim_naics.reset_index(drop=True, inplace=True)\n",
    "dim_naics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sba_office_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sba_office_code\n",
       "0             1084\n",
       "1              459\n",
       "2              470\n",
       "3              405\n",
       "4              669"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_sba_office = clean_ppp_data[['sba_office_code']].drop_duplicates()\n",
    "dim_sba_office = dim_sba_office.reset_index(drop=True)\n",
    "dim_sba_office.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_geography = clean_gdp_data[['geofips', 'geo_name', 'region']].drop_duplicates()\n",
    "dim_geography = dim_geography.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/2419124348.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace('*', '')\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/2419124348.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' (Independent City)', '')\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_52867/2419124348.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(r'(.+),.+,', r'\\1,')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>geofips</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2275</td>\n",
       "      <td>Wrangell, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2282</td>\n",
       "      <td>Yakutat, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2290</td>\n",
       "      <td>Yukon-Koyukuk, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4001</td>\n",
       "      <td>Apache, AZ</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  geofips           geo_name region\n",
       "0                  0      United States       \n",
       "1               1000            Alabama      5\n",
       "2               1001        Autauga, AL      5\n",
       "3               1003        Baldwin, AL      5\n",
       "4               1005        Barbour, AL      5\n",
       "..               ...                ...    ...\n",
       "95              2275       Wrangell, AK      8\n",
       "96              2282        Yakutat, AK      8\n",
       "97              2290  Yukon-Koyukuk, AK      8\n",
       "98              4000            Arizona      6\n",
       "99              4001         Apache, AZ      6\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the * from the geo_name\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace('*', '')\n",
    "\n",
    "#Remove the County, Parish, Borough, Census Area, Municipality, City and Borough, (Independent City) from the geo_name\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' City and Borough', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Borough', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Census Area', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Municipality', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' (Independent City)', '')\n",
    "\n",
    "# Special cases. Ex: Augusta, Staunton + Waynesboro, VA -> Augusta, VA\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(r'(.+),.+,', r'\\1,')\n",
    "\n",
    "# Remove any other records with + in the geo_name\n",
    "dim_geography = dim_geography[~dim_geography['geo_name'].str.contains('\\+')]\n",
    "\n",
    "dim_geography.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>geofips</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>region</th>\n",
       "      <th>project_state</th>\n",
       "      <th>project_county_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "      <td>All States</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2275</td>\n",
       "      <td>Wrangell, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Wrangell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2282</td>\n",
       "      <td>Yakutat, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Yakutat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2290</td>\n",
       "      <td>Yukon-Koyukuk, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Yukon-Koyukuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4001</td>\n",
       "      <td>Apache, AZ</td>\n",
       "      <td>6</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  geofips           geo_name region project_state  \\\n",
       "0                  0      United States           All States   \n",
       "1               1000            Alabama      5       Alabama   \n",
       "2               1001        Autauga, AL      5            AL   \n",
       "3               1003        Baldwin, AL      5            AL   \n",
       "4               1005        Barbour, AL      5            AL   \n",
       "..               ...                ...    ...           ...   \n",
       "95              2275       Wrangell, AK      8            AK   \n",
       "96              2282        Yakutat, AK      8            AK   \n",
       "97              2290  Yukon-Koyukuk, AK      8            AK   \n",
       "98              4000            Arizona      6       Arizona   \n",
       "99              4001         Apache, AZ      6            AZ   \n",
       "\n",
       "Description project_county_name  \n",
       "0                  All Counties  \n",
       "1                  All Counties  \n",
       "2                       Autauga  \n",
       "3                       Baldwin  \n",
       "4                       Barbour  \n",
       "..                          ...  \n",
       "95                     Wrangell  \n",
       "96                      Yakutat  \n",
       "97                Yukon-Koyukuk  \n",
       "98                 All Counties  \n",
       "99                       Apache  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split the geo_name into project_state and project_county_name\n",
    "dim_geography['project_state'] = dim_geography['geo_name'].str.split(',').str[1].str.strip()\n",
    "dim_geography['project_county_name'] = dim_geography['geo_name'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Temporarily set geofips to string\n",
    "dim_geography['geofips'] = dim_geography['geofips'].astype(str)\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].astype(str)\n",
    "\n",
    "# Set the project_state and project_county_name for the United States\n",
    "dim_geography.loc[dim_geography['geofips'] == '0', 'project_state'] = 'All States'\n",
    "dim_geography.loc[dim_geography['geofips'] == '0', 'project_county_name'] = 'All Counties'\n",
    "\n",
    "# Set the project_state and project_county_name for the States\n",
    "dim_geography.loc[dim_geography['geofips'].str.endswith('000'), 'project_state'] = dim_geography['geo_name']\n",
    "dim_geography.loc[dim_geography['geofips'].str.endswith('000'), 'project_county_name'] = 'All Counties'\n",
    "\n",
    "# Set the data types\n",
    "dim_geography['geofips'] = dim_geography['geofips'].astype(int)\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['region'] = dim_geography['region'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['project_state'] = dim_geography['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['project_county_name'] = dim_geography['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the clean_ppp_data, create the GEONAME column using the project_state and project_county_name\n",
    "# Make project_state and project_county_name as string\n",
    "clean_ppp_data['project_state'] = clean_ppp_data['project_state'].astype(str)\n",
    "clean_ppp_data['project_county_name'] = clean_ppp_data['project_county_name'].astype(str)\n",
    "clean_ppp_data['geo_name'] = clean_ppp_data['project_county_name'] + ', ' + clean_ppp_data['project_state']\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_geography to get the geofips\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_geography[['geo_name', 'geofips']], on='geo_name', how='left', suffixes=('', '_dim_geography'))\n",
    "# Delete the records that have no geofips in the clean_ppp_data\n",
    "clean_ppp_data = clean_ppp_data.dropna(subset=['geofips'])\n",
    "\n",
    "# Set the data types of the columns\n",
    "clean_ppp_data['geofips'] = clean_ppp_data['geofips'].astype(int)\n",
    "clean_ppp_data['project_state'] = clean_ppp_data['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "clean_ppp_data['project_county_name'] = clean_ppp_data['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "clean_ppp_data['geo_name'] = clean_ppp_data['geo_name'].astype(pd.StringDtype(\"pyarrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originating_lender_id</th>\n",
       "      <th>originating_lender_location_id</th>\n",
       "      <th>originating_lender</th>\n",
       "      <th>originating_lender_city</th>\n",
       "      <th>originating_lender_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>116975</td>\n",
       "      <td>Northrim Bank</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89628</td>\n",
       "      <td>National Cooperative Bank, National Association</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3386</td>\n",
       "      <td>First National Bank Alaska</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>119918</td>\n",
       "      <td>East West Bank</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>225134</td>\n",
       "      <td>Truist Bank</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   originating_lender_id  originating_lender_location_id  \\\n",
       "0                      1                          116975   \n",
       "1                      2                           89628   \n",
       "2                      3                            3386   \n",
       "3                      4                          119918   \n",
       "4                      5                          225134   \n",
       "\n",
       "                                originating_lender originating_lender_city  \\\n",
       "0                                    Northrim Bank               Anchorage   \n",
       "1  National Cooperative Bank, National Association               Hillsboro   \n",
       "2                       First National Bank Alaska               Anchorage   \n",
       "3                                   East West Bank                Pasadena   \n",
       "4                                      Truist Bank               Charlotte   \n",
       "\n",
       "  originating_lender_state  \n",
       "0                       AK  \n",
       "1                       OH  \n",
       "2                       AK  \n",
       "3                       CA  \n",
       "4                       NC  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_originating_lender = clean_ppp_data[['originating_lender_location_id', 'originating_lender', 'originating_lender_city', 'originating_lender_state']].drop_duplicates()\n",
    "dim_originating_lender[\"originating_lender_id\"] = range(1, len(dim_originating_lender) + 1)\n",
    "# Change column order\n",
    "dim_originating_lender = dim_originating_lender[['originating_lender_id', 'originating_lender_location_id', 'originating_lender', 'originating_lender_city', 'originating_lender_state']]\n",
    "# Reset the index\n",
    "dim_originating_lender = dim_originating_lender.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_originating_lender to get the originating_lender_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_originating_lender[['originating_lender_location_id', 'originating_lender_id']], on='originating_lender_location_id', how='left', suffixes=('', '_dim_originating_lender'))\n",
    "\n",
    "dim_originating_lender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borrower_id</th>\n",
       "      <th>borrower_name</th>\n",
       "      <th>borrower_address</th>\n",
       "      <th>borrower_city</th>\n",
       "      <th>borrower_state</th>\n",
       "      <th>borrower_zip</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>veteran</th>\n",
       "      <th>franchise_name</th>\n",
       "      <th>nonprofit</th>\n",
       "      <th>jobs_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>KAKIVIK ASSET MANAGEMENT, LLC</td>\n",
       "      <td>5015 Business Park Blvd</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503-7146</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARCTIC SLOPE NATIVE ASSOCIATION, LTD.</td>\n",
       "      <td>7000 Uula St</td>\n",
       "      <td>Barrow</td>\n",
       "      <td>AK</td>\n",
       "      <td>99723</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HOPE COMMUNITY RESOURCES INC.</td>\n",
       "      <td>540 W Intl Airport Rd</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99518-1105</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SOUTH PENINSULA HOSPITAL INC</td>\n",
       "      <td>4300 Bartlett Street</td>\n",
       "      <td>Homer</td>\n",
       "      <td>AK</td>\n",
       "      <td>99603</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>COPPER RIVER SEAFOODS, INC.</td>\n",
       "      <td>1118 5Th Ave</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99501-2759</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Male Owned</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   borrower_id                          borrower_name  \\\n",
       "0            1          KAKIVIK ASSET MANAGEMENT, LLC   \n",
       "1            2  ARCTIC SLOPE NATIVE ASSOCIATION, LTD.   \n",
       "2            3          HOPE COMMUNITY RESOURCES INC.   \n",
       "3            4           SOUTH PENINSULA HOSPITAL INC   \n",
       "4            5            COPPER RIVER SEAFOODS, INC.   \n",
       "\n",
       "          borrower_address borrower_city borrower_state borrower_zip  \\\n",
       "0  5015 Business Park Blvd     Anchorage             AK   99503-7146   \n",
       "1             7000 Uula St        Barrow             AK        99723   \n",
       "2    540 W Intl Airport Rd     Anchorage             AK   99518-1105   \n",
       "3     4300 Bartlett Street         Homer             AK        99603   \n",
       "4             1118 5Th Ave     Anchorage             AK   99501-2759   \n",
       "\n",
       "         race          ethnicity      gender  veteran franchise_name  \\\n",
       "0  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "1  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "2  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "3  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "4  Unanswered  Unknown/NotStated  Male Owned     True           <NA>   \n",
       "\n",
       "   nonprofit  jobs_reported  \n",
       "0      False            385  \n",
       "1       True            295  \n",
       "2       True            500  \n",
       "3      False            439  \n",
       "4      False            303  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_borrower = clean_ppp_data[['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip', 'race', 'ethnicity', 'gender', 'veteran', 'franchise_name', 'nonprofit', 'jobs_reported']].drop_duplicates()\n",
    "dim_borrower[\"borrower_id\"] = range(1, len(dim_borrower) + 1)\n",
    "# Change the column order\n",
    "dim_borrower = dim_borrower[['borrower_id', 'borrower_name', 'borrower_address', 'borrower_city','borrower_state', 'borrower_zip', 'race', 'ethnicity', 'gender', 'veteran', 'franchise_name', 'nonprofit', 'jobs_reported']]\n",
    "\n",
    "# Reset the index\n",
    "dim_borrower = dim_borrower.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_borrower to get the borrower_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_borrower[['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip', 'borrower_id']], on=['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip'], how='left', suffixes=('', '_dim_borrower'))\n",
    "dim_borrower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>servicing_lender_id</th>\n",
       "      <th>servicing_lender_location_id</th>\n",
       "      <th>servicing_lender_name</th>\n",
       "      <th>servicing_lender_address</th>\n",
       "      <th>servicing_lender_city</th>\n",
       "      <th>servicing_lender_state</th>\n",
       "      <th>servicing_lender_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>116975</td>\n",
       "      <td>Northrim Bank</td>\n",
       "      <td>3111 'C' St</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89628</td>\n",
       "      <td>National Cooperative Bank, National Association</td>\n",
       "      <td>139 S High St</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OH</td>\n",
       "      <td>45133-1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3386</td>\n",
       "      <td>First National Bank Alaska</td>\n",
       "      <td>101 W 36th Ave</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503-5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>119918</td>\n",
       "      <td>East West Bank</td>\n",
       "      <td>135 N Los Robles Ave, 7th Fl</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>91101-4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>225134</td>\n",
       "      <td>Truist Bank</td>\n",
       "      <td>214 N Tryon St</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>28202-1078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   servicing_lender_id  servicing_lender_location_id  \\\n",
       "0                    1                        116975   \n",
       "1                    2                         89628   \n",
       "2                    3                          3386   \n",
       "3                    4                        119918   \n",
       "4                    5                        225134   \n",
       "\n",
       "                             servicing_lender_name  \\\n",
       "0                                    Northrim Bank   \n",
       "1  National Cooperative Bank, National Association   \n",
       "2                       First National Bank Alaska   \n",
       "3                                   East West Bank   \n",
       "4                                      Truist Bank   \n",
       "\n",
       "       servicing_lender_address servicing_lender_city servicing_lender_state  \\\n",
       "0                   3111 'C' St             Anchorage                     AK   \n",
       "1                 139 S High St             Hillsboro                     OH   \n",
       "2                101 W 36th Ave             Anchorage                     AK   \n",
       "3  135 N Los Robles Ave, 7th Fl              Pasadena                     CA   \n",
       "4                214 N Tryon St             Charlotte                     NC   \n",
       "\n",
       "  servicing_lender_zip  \n",
       "0                99503  \n",
       "1           45133-1442  \n",
       "2           99503-5904  \n",
       "3           91101-4525  \n",
       "4           28202-1078  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_servicing_lender = clean_ppp_data[['servicing_lender_location_id', 'servicing_lender_name', 'servicing_lender_address', 'servicing_lender_city', 'servicing_lender_state', 'servicing_lender_zip']].drop_duplicates()\n",
    "dim_servicing_lender[\"servicing_lender_id\"] = range(1, len(dim_servicing_lender) + 1)\n",
    "\n",
    "# Reset the index\n",
    "dim_servicing_lender = dim_servicing_lender.reset_index(drop=True)\n",
    "\n",
    "# Change the column order\n",
    "dim_servicing_lender = dim_servicing_lender[['servicing_lender_id', 'servicing_lender_location_id', 'servicing_lender_name', 'servicing_lender_address', 'servicing_lender_city', 'servicing_lender_state', 'servicing_lender_zip']]\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_servicing_lender to get the servicing_lender_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_servicing_lender[['servicing_lender_location_id', 'servicing_lender_id']], on='servicing_lender_location_id', how='left', suffixes=('', '_dim_servicing_lender'))\n",
    "dim_servicing_lender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Factorize to create tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status_id</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paid in Full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status_id   loan_status\n",
       "0               1  Paid in Full\n",
       "1               2   Charged Off"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_loan_status = clean_ppp_data[['loan_status']].drop_duplicates()\n",
    "dim_loan_status[\"loan_status_id\"] = range(1, len(dim_loan_status) + 1)\n",
    "# Change the column order\n",
    "dim_loan_status = dim_loan_status[['loan_status_id', 'loan_status']]\n",
    "# Reset the index\n",
    "dim_loan_status = dim_loan_status.reset_index(drop=True)\n",
    "# Merge the clean_ppp_data with the dim_loan_status to get the loan_status_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_loan_status[['loan_status', 'loan_status_id']], on='loan_status', how='left', suffixes=('', '_dim_loan_status'))\n",
    "dim_loan_status.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_type_id</th>\n",
       "      <th>business_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Limited  Liability Company(LLC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-Profit Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>501(c)3 – Non Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Subchapter S Corporation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_type_id                    business_type\n",
       "0                 1  Limited  Liability Company(LLC)\n",
       "1                 2          Non-Profit Organization\n",
       "2                 3             501(c)3 – Non Profit\n",
       "3                 4                      Corporation\n",
       "4                 5         Subchapter S Corporation"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_business_type = clean_ppp_data[['business_type']].drop_duplicates()\n",
    "dim_business_type[\"business_type_id\"] = range(1, len(dim_business_type) + 1)\n",
    "\n",
    "# Change the column order\n",
    "dim_business_type = dim_business_type[['business_type_id', 'business_type']]\n",
    "\n",
    "# Reset the index\n",
    "dim_business_type = dim_business_type.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_business_type to get the business_type_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_business_type[['business_type', 'business_type_id']], on='business_type', how='left', suffixes=('', '_dim_business_type'))\n",
    "dim_business_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processing_method_id</th>\n",
       "      <th>processing_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   processing_method_id processing_method\n",
       "0                     1               PPP\n",
       "1                     2               PPS"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_processing_method = clean_ppp_data[['processing_method']].drop_duplicates()\n",
    "dim_processing_method[\"processing_method_id\"] = range(1, len(dim_processing_method) + 1)\n",
    "dim_processing_method = dim_processing_method[['processing_method_id', 'processing_method']]\n",
    "dim_processing_method = dim_processing_method.reset_index(drop=True)\n",
    "\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_processing_method[['processing_method', 'processing_method_id']], on='processing_method', how='left', suffixes=('', '_dim_processing_method'))\n",
    "\n",
    "dim_processing_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term_id  term_month\n",
       "0        1           0\n",
       "1        2           1\n",
       "2        3           2\n",
       "3        4           3\n",
       "4        5           4"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_term = clean_ppp_data[['term_month']].drop_duplicates()\n",
    "dim_term = dim_term.sort_values(by='term_month')\n",
    "dim_term[\"term_id\"] = range(1, len(dim_term) + 1)\n",
    "dim_term = dim_term[['term_id', 'term_month']]\n",
    "dim_term = dim_term.reset_index(drop=True)\n",
    "\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_term[['term_month', 'term_id']], on='term_month', how='left', suffixes=('', '_dim_term'))\n",
    "\n",
    "dim_term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_business_age = clean_ppp_data[['business_age_description']].drop_duplicates()\n",
    "dim_business_age[\"business_age_id\"] = range(1, len(dim_business_age) + 1)\n",
    "dim_business_age = dim_business_age[['business_age_id', 'business_age_description']]\n",
    "dim_business_age = dim_business_age.reset_index(drop=True)\n",
    "\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_business_age[['business_age_description', 'business_age_id']], on='business_age_description', how='left', suffixes=('', '_dim_business_age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_ppp_id</th>\n",
       "      <th>loan_number</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>geofips</th>\n",
       "      <th>date_approved_id</th>\n",
       "      <th>loan_status_date_id</th>\n",
       "      <th>forgiveness_date_id</th>\n",
       "      <th>borrower_id</th>\n",
       "      <th>originating_lender_id</th>\n",
       "      <th>servicing_lender_id</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_status_id</th>\n",
       "      <th>processing_method_id</th>\n",
       "      <th>sba_office_code</th>\n",
       "      <th>business_age_id</th>\n",
       "      <th>business_type_id</th>\n",
       "      <th>sba_guaranty_percentage</th>\n",
       "      <th>initial_approval_amount</th>\n",
       "      <th>current_approval_amount</th>\n",
       "      <th>undisbursed_amount</th>\n",
       "      <th>forgiveness_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9621894</th>\n",
       "      <td>9922510</td>\n",
       "      <td>9680978809</td>\n",
       "      <td>621399</td>\n",
       "      <td>41029</td>\n",
       "      <td>2021042300</td>\n",
       "      <td>2021091600</td>\n",
       "      <td>2021082500</td>\n",
       "      <td>8892917</td>\n",
       "      <td>1222</td>\n",
       "      <td>1085</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.9</td>\n",
       "      <td>10867.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10903.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621895</th>\n",
       "      <td>9922511</td>\n",
       "      <td>9108608900</td>\n",
       "      <td>114111</td>\n",
       "      <td>41007</td>\n",
       "      <td>2021051200</td>\n",
       "      <td>2022011500</td>\n",
       "      <td>2021122800</td>\n",
       "      <td>8892918</td>\n",
       "      <td>1664</td>\n",
       "      <td>1528</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.7</td>\n",
       "      <td>10867.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10934.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621896</th>\n",
       "      <td>9922512</td>\n",
       "      <td>4327788404</td>\n",
       "      <td>111140</td>\n",
       "      <td>41021</td>\n",
       "      <td>2021020600</td>\n",
       "      <td>2021071300</td>\n",
       "      <td>2021062500</td>\n",
       "      <td>8892919</td>\n",
       "      <td>750</td>\n",
       "      <td>699</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10905.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621897</th>\n",
       "      <td>9922513</td>\n",
       "      <td>5314208607</td>\n",
       "      <td>713990</td>\n",
       "      <td>41007</td>\n",
       "      <td>2021032000</td>\n",
       "      <td>2021081100</td>\n",
       "      <td>2021071900</td>\n",
       "      <td>8892920</td>\n",
       "      <td>4358</td>\n",
       "      <td>3980</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10901.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621898</th>\n",
       "      <td>9922514</td>\n",
       "      <td>1686668706</td>\n",
       "      <td>541110</td>\n",
       "      <td>41051</td>\n",
       "      <td>2021032700</td>\n",
       "      <td>2021041300</td>\n",
       "      <td>2022042700</td>\n",
       "      <td>8892921</td>\n",
       "      <td>383</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10865.0</td>\n",
       "      <td>10865.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10980.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         facts_ppp_id  loan_number  naics_code  geofips  date_approved_id  \\\n",
       "9621894       9922510   9680978809      621399    41029        2021042300   \n",
       "9621895       9922511   9108608900      114111    41007        2021051200   \n",
       "9621896       9922512   4327788404      111140    41021        2021020600   \n",
       "9621897       9922513   5314208607      713990    41007        2021032000   \n",
       "9621898       9922514   1686668706      541110    41051        2021032700   \n",
       "\n",
       "         loan_status_date_id  forgiveness_date_id  borrower_id  \\\n",
       "9621894           2021091600           2021082500      8892917   \n",
       "9621895           2022011500           2021122800      8892918   \n",
       "9621896           2021071300           2021062500      8892919   \n",
       "9621897           2021081100           2021071900      8892920   \n",
       "9621898           2021041300           2022042700      8892921   \n",
       "\n",
       "         originating_lender_id  servicing_lender_id  ...  loan_status_id  \\\n",
       "9621894                   1222                 1085  ...               1   \n",
       "9621895                   1664                 1528  ...               1   \n",
       "9621896                    750                  699  ...               1   \n",
       "9621897                   4358                 3980  ...               1   \n",
       "9621898                    383                  152  ...               1   \n",
       "\n",
       "         processing_method_id  sba_office_code  business_age_id  \\\n",
       "9621894                     2             1086                1   \n",
       "9621895                     2             1086                1   \n",
       "9621896                     1             1086                1   \n",
       "9621897                     1             1086                1   \n",
       "9621898                     2             1086                1   \n",
       "\n",
       "         business_type_id  sba_guaranty_percentage  initial_approval_amount  \\\n",
       "9621894                 9                    100.0                  10867.9   \n",
       "9621895                 9                    100.0                  10867.7   \n",
       "9621896                 9                    100.0                  10867.0   \n",
       "9621897                 9                    100.0                  10867.0   \n",
       "9621898                 5                    100.0                  10865.0   \n",
       "\n",
       "         current_approval_amount  undisbursed_amount  forgiveness_amount  \n",
       "9621894                  10867.9                 0.0            10903.03  \n",
       "9621895                  10867.7                 0.0            10934.39  \n",
       "9621896                  10867.0                 0.0            10905.11  \n",
       "9621897                  10867.0                 0.0            10901.54  \n",
       "9621898                  10865.0                 0.0            10980.94  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fact_ppp = clean_ppp_data[['facts_ppp_id', 'loan_number', 'naics_code', 'geofips', 'date_approved_id', 'loan_status_date_id', 'forgiveness_date_id', 'borrower_id', 'originating_lender_id', 'servicing_lender_id', 'term_id', 'loan_status_id', 'processing_method_id', 'sba_office_code', 'business_age_id', 'business_type_id', 'sba_guaranty_percentage', 'initial_approval_amount', 'current_approval_amount', 'undisbursed_amount', 'forgiveness_amount']]\n",
    "fact_ppp = fact_ppp.reset_index(drop=True)\n",
    "fact_ppp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>facts_gdp_id</th>\n",
       "      <th>year_id</th>\n",
       "      <th>real_gdp</th>\n",
       "      <th>chain_type_index_gdp</th>\n",
       "      <th>current_dollar_gdp</th>\n",
       "      <th>geofips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017010100</td>\n",
       "      <td>1.961210e+10</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.961210e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018010100</td>\n",
       "      <td>2.019390e+10</td>\n",
       "      <td>102.967</td>\n",
       "      <td>2.065652e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019010100</td>\n",
       "      <td>2.069209e+10</td>\n",
       "      <td>105.507</td>\n",
       "      <td>2.152140e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2020010100</td>\n",
       "      <td>2.023407e+10</td>\n",
       "      <td>103.171</td>\n",
       "      <td>2.132295e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2021010100</td>\n",
       "      <td>2.140769e+10</td>\n",
       "      <td>109.156</td>\n",
       "      <td>2.359403e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2022010100</td>\n",
       "      <td>2.182204e+10</td>\n",
       "      <td>111.268</td>\n",
       "      <td>2.574411e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2017010100</td>\n",
       "      <td>2.166155e+08</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.166155e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2018010100</td>\n",
       "      <td>2.208088e+08</td>\n",
       "      <td>101.936</td>\n",
       "      <td>2.262638e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2019010100</td>\n",
       "      <td>2.249446e+08</td>\n",
       "      <td>103.845</td>\n",
       "      <td>2.345264e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2020010100</td>\n",
       "      <td>2.220814e+08</td>\n",
       "      <td>102.523</td>\n",
       "      <td>2.351183e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2021010100</td>\n",
       "      <td>2.318926e+08</td>\n",
       "      <td>107.053</td>\n",
       "      <td>2.579865e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2022010100</td>\n",
       "      <td>2.358073e+08</td>\n",
       "      <td>108.860</td>\n",
       "      <td>2.815690e+08</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2017010100</td>\n",
       "      <td>1.762558e+06</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.762558e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2018010100</td>\n",
       "      <td>1.787534e+06</td>\n",
       "      <td>101.417</td>\n",
       "      <td>1.826642e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2019010100</td>\n",
       "      <td>1.730861e+06</td>\n",
       "      <td>98.202</td>\n",
       "      <td>1.804013e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2020010100</td>\n",
       "      <td>1.722438e+06</td>\n",
       "      <td>97.724</td>\n",
       "      <td>1.813553e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2021010100</td>\n",
       "      <td>1.727818e+06</td>\n",
       "      <td>98.029</td>\n",
       "      <td>1.947622e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2022010100</td>\n",
       "      <td>1.929264e+06</td>\n",
       "      <td>109.458</td>\n",
       "      <td>2.364891e+06</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2017010100</td>\n",
       "      <td>7.382558e+06</td>\n",
       "      <td>100.000</td>\n",
       "      <td>7.382558e+06</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2018010100</td>\n",
       "      <td>7.758980e+06</td>\n",
       "      <td>105.099</td>\n",
       "      <td>7.935575e+06</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  facts_gdp_id     year_id      real_gdp  chain_type_index_gdp  \\\n",
       "0                       1  2017010100  1.961210e+10               100.000   \n",
       "1                       2  2018010100  2.019390e+10               102.967   \n",
       "2                       3  2019010100  2.069209e+10               105.507   \n",
       "3                       4  2020010100  2.023407e+10               103.171   \n",
       "4                       5  2021010100  2.140769e+10               109.156   \n",
       "5                       6  2022010100  2.182204e+10               111.268   \n",
       "6                       7  2017010100  2.166155e+08               100.000   \n",
       "7                       8  2018010100  2.208088e+08               101.936   \n",
       "8                       9  2019010100  2.249446e+08               103.845   \n",
       "9                      10  2020010100  2.220814e+08               102.523   \n",
       "10                     11  2021010100  2.318926e+08               107.053   \n",
       "11                     12  2022010100  2.358073e+08               108.860   \n",
       "12                     13  2017010100  1.762558e+06               100.000   \n",
       "13                     14  2018010100  1.787534e+06               101.417   \n",
       "14                     15  2019010100  1.730861e+06                98.202   \n",
       "15                     16  2020010100  1.722438e+06                97.724   \n",
       "16                     17  2021010100  1.727818e+06                98.029   \n",
       "17                     18  2022010100  1.929264e+06               109.458   \n",
       "18                     19  2017010100  7.382558e+06               100.000   \n",
       "19                     20  2018010100  7.758980e+06               105.099   \n",
       "\n",
       "Description  current_dollar_gdp  geofips  \n",
       "0                  1.961210e+10        0  \n",
       "1                  2.065652e+10        0  \n",
       "2                  2.152140e+10        0  \n",
       "3                  2.132295e+10        0  \n",
       "4                  2.359403e+10        0  \n",
       "5                  2.574411e+10        0  \n",
       "6                  2.166155e+08     1000  \n",
       "7                  2.262638e+08     1000  \n",
       "8                  2.345264e+08     1000  \n",
       "9                  2.351183e+08     1000  \n",
       "10                 2.579865e+08     1000  \n",
       "11                 2.815690e+08     1000  \n",
       "12                 1.762558e+06     1001  \n",
       "13                 1.826642e+06     1001  \n",
       "14                 1.804013e+06     1001  \n",
       "15                 1.813553e+06     1001  \n",
       "16                 1.947622e+06     1001  \n",
       "17                 2.364891e+06     1001  \n",
       "18                 7.382558e+06     1003  \n",
       "19                 7.935575e+06     1003  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Fact Table\n",
    "facts_gdp = clean_gdp_data[['facts_gdp_id', 'year_id', 'real_gdp', 'chain_type_index_gdp', 'current_dollar_gdp', 'geofips']]\n",
    "facts_gdp.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Dimension\n",
    "Start date: 2017-01-01 00:00:00 \n",
    "\n",
    "2017 is the minimum year in the GDP data\n",
    "\n",
    "End date: 2023-10-1 00:00:00 \n",
    "\n",
    "October 2023 is the maximum date in the PPP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>date_iso_format</th>\n",
       "      <th>year_number</th>\n",
       "      <th>quarter_number</th>\n",
       "      <th>month_number</th>\n",
       "      <th>day_number</th>\n",
       "      <th>hour_number</th>\n",
       "      <th>month_name</th>\n",
       "      <th>day_name</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>week_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017010100</td>\n",
       "      <td>2017-01-01T00:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017010101</td>\n",
       "      <td>2017-01-01T01:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017010102</td>\n",
       "      <td>2017-01-01T02:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017010103</td>\n",
       "      <td>2017-01-01T03:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017010104</td>\n",
       "      <td>2017-01-01T04:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017010105</td>\n",
       "      <td>2017-01-01T05:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017010106</td>\n",
       "      <td>2017-01-01T06:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017010107</td>\n",
       "      <td>2017-01-01T07:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017010108</td>\n",
       "      <td>2017-01-01T08:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017010109</td>\n",
       "      <td>2017-01-01T09:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_id      date_iso_format  year_number  quarter_number  month_number  \\\n",
       "0  2017010100  2017-01-01T00:00:00         2017               1             1   \n",
       "1  2017010101  2017-01-01T01:00:00         2017               1             1   \n",
       "2  2017010102  2017-01-01T02:00:00         2017               1             1   \n",
       "3  2017010103  2017-01-01T03:00:00         2017               1             1   \n",
       "4  2017010104  2017-01-01T04:00:00         2017               1             1   \n",
       "5  2017010105  2017-01-01T05:00:00         2017               1             1   \n",
       "6  2017010106  2017-01-01T06:00:00         2017               1             1   \n",
       "7  2017010107  2017-01-01T07:00:00         2017               1             1   \n",
       "8  2017010108  2017-01-01T08:00:00         2017               1             1   \n",
       "9  2017010109  2017-01-01T09:00:00         2017               1             1   \n",
       "\n",
       "   day_number  hour_number month_name day_name week_of_year  week_of_month  \n",
       "0           1            0    January   Sunday           01              1  \n",
       "1           1            1    January   Sunday           01              1  \n",
       "2           1            2    January   Sunday           01              1  \n",
       "3           1            3    January   Sunday           01              1  \n",
       "4           1            4    January   Sunday           01              1  \n",
       "5           1            5    January   Sunday           01              1  \n",
       "6           1            6    January   Sunday           01              1  \n",
       "7           1            7    January   Sunday           01              1  \n",
       "8           1            8    January   Sunday           01              1  \n",
       "9           1            9    January   Sunday           01              1  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def week_of_month(dt):\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "    week_number = (day - 1) // 7 + 1\n",
    "    return week_number\n",
    "\n",
    "start_date = pd.to_datetime('2017-01-01 00:00:00') #2017 is the start date in the GDP data\n",
    "end_date = pd.to_datetime('2023-10-01 00:00:00') # 2023 is the end date in the PPP data\n",
    "\n",
    "# Create a DataFrame for the date dimension\n",
    "date_dimension = pd.DataFrame({'date': pd.date_range(start_date, end_date, freq='H')})\n",
    "\n",
    "# Extract attributes\n",
    "date_dimension['year_number'] = date_dimension['date'].dt.year\n",
    "date_dimension['quarter_number'] = date_dimension['date'].dt.quarter #quarter_number\n",
    "date_dimension['month_number'] = date_dimension['date'].dt.month\n",
    "date_dimension['month_name'] = date_dimension['date'].dt.strftime('%B')\n",
    "date_dimension['day_number'] = date_dimension['date'].dt.day #day_number\n",
    "date_dimension['day_name'] = date_dimension['date'].dt.strftime('%A') #day_name\n",
    "date_dimension['hour_number'] = date_dimension['date'].dt.hour #hour_number\n",
    "date_dimension['date_iso_format'] = date_dimension['date'].apply(lambda x: x.isoformat())\n",
    "date_dimension['date_id'] = date_dimension['date'].dt.strftime('%Y%m%d%H')\n",
    "\n",
    "# Add week of the month and week of the year\n",
    "date_dimension['week_of_month'] = date_dimension['date'].apply(week_of_month) #week_of_month\n",
    "date_dimension['week_of_year'] = date_dimension['date'].dt.strftime('%U') #week_of_year\n",
    "\n",
    "new_order = ['date_id', 'date_iso_format','year_number','quarter_number','month_number','day_number','hour_number','month_name','day_name','week_of_year','week_of_month']\n",
    "date_dimension = date_dimension[new_order]\n",
    "\n",
    "date_dimension.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into the Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "(psycopg2.DatabaseError) SSL SYSCALL error: Operation timed out\n\n[SQL: INSERT INTO fact_ppp (facts_ppp_id, loan_number, naics_code, geofips, date_approved_id, loan_status_date_id, forgiveness_date_id, borrower_id, originating_lender_id, servicing_lender_id, term_id, loan_status_id, processing_method_id, sba_office_code, business_age_id, business_type_id, sba_guaranty_percentage, initial_approval_amount, current_approval_amount, undisbursed_amount, forgiveness_amount) VALUES (%(facts_ppp_id)s, %(loan_number)s, %(naics_code)s, %(geofips)s, %(date_approved_id)s, %(loan_status_date_id)s, %(forgiveness_date_id)s, %(borrower_id)s, %(originating_lender_id)s, %(servicing_lender_id)s, %(term_id)s, %(loan_status_id)s, %(processing_method_id)s, %(sba_office_code)s, %(business_age_id)s, %(business_type_id)s, %(sba_guaranty_percentage)s, %(initial_approval_amount)s, %(current_approval_amount)s, %(undisbursed_amount)s, %(forgiveness_amount)s)]\n[parameters: ({'facts_ppp_id': 1, 'loan_number': 5502308207, 'naics_code': 541990, 'geofips': 2020, 'date_approved_id': 2020080800, 'loan_status_date_id': 2021072200, 'forgiveness_date_id': 2021061100, 'borrower_id': 1, 'originating_lender_id': 1, 'servicing_lender_id': 1, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 9571397.0, 'current_approval_amount': 9538531.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 9615884.57}, {'facts_ppp_id': 2, 'loan_number': 6110847106, 'naics_code': 813920, 'geofips': 2185, 'date_approved_id': 2020041400, 'loan_status_date_id': 2021082100, 'forgiveness_date_id': 2021071300, 'borrower_id': 2, 'originating_lender_id': 2, 'servicing_lender_id': 2, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 2, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 7666768.0, 'current_approval_amount': 7666768.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 7761324.81}, {'facts_ppp_id': 3, 'loan_number': 5120868804, 'naics_code': 624120, 'geofips': 2020, 'date_approved_id': 2021041700, 'loan_status_date_id': 2022100600, 'forgiveness_date_id': 2022091300, 'borrower_id': 3, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 3, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 7223025.0, 'current_approval_amount': 7223025.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 7321970.55}, {'facts_ppp_id': 4, 'loan_number': 6650277102, 'naics_code': 622110, 'geofips': 2122, 'date_approved_id': 2020041400, 'loan_status_date_id': 2021060900, 'forgiveness_date_id': 2021051800, 'borrower_id': 4, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 6528631.4, 'current_approval_amount': 6528631.4, 'undisbursed_amount': 0.0, 'forgiveness_amount': 6598389.38}, {'facts_ppp_id': 5, 'loan_number': 3323817108, 'naics_code': 311710, 'geofips': 2020, 'date_approved_id': 2020041100, 'loan_status_date_id': 2021081300, 'forgiveness_date_id': 2021070700, 'borrower_id': 5, 'originating_lender_id': 4, 'servicing_lender_id': 4, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 3009400.0, 'current_approval_amount': 6382400.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 6461470.84}, {'facts_ppp_id': 7, 'loan_number': 6197677007, 'naics_code': 213112, 'geofips': 2020, 'date_approved_id': 2020040600, 'loan_status_date_id': 2021082000, 'forgiveness_date_id': 2021072800, 'borrower_id': 6, 'originating_lender_id': 1, 'servicing_lender_id': 1, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 5095098.0, 'current_approval_amount': 5095098.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 5161124.89}, {'facts_ppp_id': 8, 'loan_number': 2256077301, 'naics_code': 621111, 'geofips': 2020, 'date_approved_id': 2020042900, 'loan_status_date_id': 2021112300, 'forgiveness_date_id': 2021110900, 'borrower_id': 7, 'originating_lender_id': 5, 'servicing_lender_id': 5, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 5036100.0, 'current_approval_amount': 5036100.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 5091776.88}, {'facts_ppp_id': 10, 'loan_number': 9643427203, 'naics_code': 221122, 'geofips': 2122, 'date_approved_id': 2020042800, 'loan_status_date_id': 2021070800, 'forgiveness_date_id': 2021061400, 'borrower_id': 8, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 4808473.42, 'current_approval_amount': 4808473.42, 'undisbursed_amount': 0.0, 'forgiveness_amount': 4861564.24}  ... displaying 10 of 9621899 total bound parameter sets ...  {'facts_ppp_id': 9922513, 'loan_number': 5314208607, 'naics_code': 713990, 'geofips': 41007, 'date_approved_id': 2021032000, 'loan_status_date_id': 2021081100, 'forgiveness_date_id': 2021071900, 'borrower_id': 8892920, 'originating_lender_id': 4358, 'servicing_lender_id': 3980, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1086, 'business_age_id': 1, 'business_type_id': 9, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 10867.0, 'current_approval_amount': 10867.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 10901.54}, {'facts_ppp_id': 9922514, 'loan_number': 1686668706, 'naics_code': 541110, 'geofips': 41051, 'date_approved_id': 2021032700, 'loan_status_date_id': 2021041300, 'forgiveness_date_id': 2022042700, 'borrower_id': 8892921, 'originating_lender_id': 383, 'servicing_lender_id': 152, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 2, 'sba_office_code': 1086, 'business_age_id': 1, 'business_type_id': 5, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 10865.0, 'current_approval_amount': 10865.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 10980.94})]\n(Background on this error at: https://sqlalche.me/e/14/4xp6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1799\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[1;32m   1800\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1801\u001b[0m         )\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:953\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    952\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[0;32m--> 953\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m xtras\u001b[38;5;241m.\u001b[39mexecute_values(\n\u001b[1;32m    954\u001b[0m         cursor,\n\u001b[1;32m    955\u001b[0m         statement,\n\u001b[1;32m    956\u001b[0m         parameters,\n\u001b[1;32m    957\u001b[0m         template\u001b[38;5;241m=\u001b[39mexecutemany_values,\n\u001b[1;32m    958\u001b[0m         fetch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(context\u001b[38;5;241m.\u001b[39mcompiled\u001b[38;5;241m.\u001b[39mreturning),\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/psycopg2/extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1299\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts))\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n",
      "\u001b[0;31mDatabaseError\u001b[0m: SSL SYSCALL error: Operation timed out\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[329], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m dim_business_age\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_business_age\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m date_dimension\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m fact_ppp\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact_ppp\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m facts_gdp\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacts_gdp\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m   2988\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2989\u001b[0m     name,\n\u001b[1;32m   2990\u001b[0m     con,\n\u001b[1;32m   2991\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   2992\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m   2993\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   2994\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   2995\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   2996\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   2997\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   2998\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m    696\u001b[0m     frame,\n\u001b[1;32m    697\u001b[0m     name,\n\u001b[1;32m    698\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m    699\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m    700\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m    701\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    702\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    703\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    704\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    705\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    707\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1726\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m   1728\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[1;32m   1729\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[1;32m   1730\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1736\u001b[0m )\n\u001b[0;32m-> 1738\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[1;32m   1739\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m   1740\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable,\n\u001b[1;32m   1741\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[1;32m   1742\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   1743\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   1744\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   1745\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   1746\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1748\u001b[0m )\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:1335\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize\u001b[38;5;241m=\u001b[39mchunksize, method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mSQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    945\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[0;32m--> 946\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:853\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    852\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[0;32m--> 853\u001b[0m result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39minsert(), data)\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   1303\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m   1304\u001b[0m     )\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\u001b[38;5;28mself\u001b[39m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    330\u001b[0m ):\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;28mself\u001b[39m, multiparams, params, execution_options\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1486\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1488\u001b[0m )\n\u001b[1;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1491\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1492\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1499\u001b[0m     dialect,\n\u001b[1;32m   1500\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[1;32m   1501\u001b[0m     compiled_sql,\n\u001b[1;32m   1502\u001b[0m     distilled_params,\n\u001b[1;32m   1503\u001b[0m     execution_options,\n\u001b[1;32m   1504\u001b[0m     compiled_sql,\n\u001b[1;32m   1505\u001b[0m     distilled_params,\n\u001b[1;32m   1506\u001b[0m     elem,\n\u001b[1;32m   1507\u001b[0m     extracted_params,\n\u001b[1;32m   1508\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1513\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1517\u001b[0m         ret,\n\u001b[1;32m   1518\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1864\u001b[0m     )\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2043\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2047\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1799\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[1;32m   1800\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1801\u001b[0m         )\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:953\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    951\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    952\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[0;32m--> 953\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m xtras\u001b[38;5;241m.\u001b[39mexecute_values(\n\u001b[1;32m    954\u001b[0m         cursor,\n\u001b[1;32m    955\u001b[0m         statement,\n\u001b[1;32m    956\u001b[0m         parameters,\n\u001b[1;32m    957\u001b[0m         template\u001b[38;5;241m=\u001b[39mexecutemany_values,\n\u001b[1;32m    958\u001b[0m         fetch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(context\u001b[38;5;241m.\u001b[39mcompiled\u001b[38;5;241m.\u001b[39mreturning),\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_batch_page_size:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/psycopg2/extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1297\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1299\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts))\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[1;32m   1301\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "\u001b[0;31mDatabaseError\u001b[0m: (psycopg2.DatabaseError) SSL SYSCALL error: Operation timed out\n\n[SQL: INSERT INTO fact_ppp (facts_ppp_id, loan_number, naics_code, geofips, date_approved_id, loan_status_date_id, forgiveness_date_id, borrower_id, originating_lender_id, servicing_lender_id, term_id, loan_status_id, processing_method_id, sba_office_code, business_age_id, business_type_id, sba_guaranty_percentage, initial_approval_amount, current_approval_amount, undisbursed_amount, forgiveness_amount) VALUES (%(facts_ppp_id)s, %(loan_number)s, %(naics_code)s, %(geofips)s, %(date_approved_id)s, %(loan_status_date_id)s, %(forgiveness_date_id)s, %(borrower_id)s, %(originating_lender_id)s, %(servicing_lender_id)s, %(term_id)s, %(loan_status_id)s, %(processing_method_id)s, %(sba_office_code)s, %(business_age_id)s, %(business_type_id)s, %(sba_guaranty_percentage)s, %(initial_approval_amount)s, %(current_approval_amount)s, %(undisbursed_amount)s, %(forgiveness_amount)s)]\n[parameters: ({'facts_ppp_id': 1, 'loan_number': 5502308207, 'naics_code': 541990, 'geofips': 2020, 'date_approved_id': 2020080800, 'loan_status_date_id': 2021072200, 'forgiveness_date_id': 2021061100, 'borrower_id': 1, 'originating_lender_id': 1, 'servicing_lender_id': 1, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 9571397.0, 'current_approval_amount': 9538531.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 9615884.57}, {'facts_ppp_id': 2, 'loan_number': 6110847106, 'naics_code': 813920, 'geofips': 2185, 'date_approved_id': 2020041400, 'loan_status_date_id': 2021082100, 'forgiveness_date_id': 2021071300, 'borrower_id': 2, 'originating_lender_id': 2, 'servicing_lender_id': 2, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 2, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 7666768.0, 'current_approval_amount': 7666768.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 7761324.81}, {'facts_ppp_id': 3, 'loan_number': 5120868804, 'naics_code': 624120, 'geofips': 2020, 'date_approved_id': 2021041700, 'loan_status_date_id': 2022100600, 'forgiveness_date_id': 2022091300, 'borrower_id': 3, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 3, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 7223025.0, 'current_approval_amount': 7223025.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 7321970.55}, {'facts_ppp_id': 4, 'loan_number': 6650277102, 'naics_code': 622110, 'geofips': 2122, 'date_approved_id': 2020041400, 'loan_status_date_id': 2021060900, 'forgiveness_date_id': 2021051800, 'borrower_id': 4, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 6528631.4, 'current_approval_amount': 6528631.4, 'undisbursed_amount': 0.0, 'forgiveness_amount': 6598389.38}, {'facts_ppp_id': 5, 'loan_number': 3323817108, 'naics_code': 311710, 'geofips': 2020, 'date_approved_id': 2020041100, 'loan_status_date_id': 2021081300, 'forgiveness_date_id': 2021070700, 'borrower_id': 5, 'originating_lender_id': 4, 'servicing_lender_id': 4, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 3009400.0, 'current_approval_amount': 6382400.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 6461470.84}, {'facts_ppp_id': 7, 'loan_number': 6197677007, 'naics_code': 213112, 'geofips': 2020, 'date_approved_id': 2020040600, 'loan_status_date_id': 2021082000, 'forgiveness_date_id': 2021072800, 'borrower_id': 6, 'originating_lender_id': 1, 'servicing_lender_id': 1, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 5095098.0, 'current_approval_amount': 5095098.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 5161124.89}, {'facts_ppp_id': 8, 'loan_number': 2256077301, 'naics_code': 621111, 'geofips': 2020, 'date_approved_id': 2020042900, 'loan_status_date_id': 2021112300, 'forgiveness_date_id': 2021110900, 'borrower_id': 7, 'originating_lender_id': 5, 'servicing_lender_id': 5, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 1, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 5036100.0, 'current_approval_amount': 5036100.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 5091776.88}, {'facts_ppp_id': 10, 'loan_number': 9643427203, 'naics_code': 221122, 'geofips': 2122, 'date_approved_id': 2020042800, 'loan_status_date_id': 2021070800, 'forgiveness_date_id': 2021061400, 'borrower_id': 8, 'originating_lender_id': 3, 'servicing_lender_id': 3, 'term_id': 25, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1084, 'business_age_id': 1, 'business_type_id': 4, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 4808473.42, 'current_approval_amount': 4808473.42, 'undisbursed_amount': 0.0, 'forgiveness_amount': 4861564.24}  ... displaying 10 of 9621899 total bound parameter sets ...  {'facts_ppp_id': 9922513, 'loan_number': 5314208607, 'naics_code': 713990, 'geofips': 41007, 'date_approved_id': 2021032000, 'loan_status_date_id': 2021081100, 'forgiveness_date_id': 2021071900, 'borrower_id': 8892920, 'originating_lender_id': 4358, 'servicing_lender_id': 3980, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 1, 'sba_office_code': 1086, 'business_age_id': 1, 'business_type_id': 9, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 10867.0, 'current_approval_amount': 10867.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 10901.54}, {'facts_ppp_id': 9922514, 'loan_number': 1686668706, 'naics_code': 541110, 'geofips': 41051, 'date_approved_id': 2021032700, 'loan_status_date_id': 2021041300, 'forgiveness_date_id': 2022042700, 'borrower_id': 8892921, 'originating_lender_id': 383, 'servicing_lender_id': 152, 'term_id': 61, 'loan_status_id': 1, 'processing_method_id': 2, 'sba_office_code': 1086, 'business_age_id': 1, 'business_type_id': 5, 'sba_guaranty_percentage': 100.0, 'initial_approval_amount': 10865.0, 'current_approval_amount': 10865.0, 'undisbursed_amount': 0.0, 'forgiveness_amount': 10980.94})]\n(Background on this error at: https://sqlalche.me/e/14/4xp6)"
     ]
    }
   ],
   "source": [
    "# Load the data into the database\n",
    "dim_naics.to_sql('dim_naics', engine, if_exists='append', index=False)\n",
    "dim_sba_office.to_sql('dim_sba_office', engine, if_exists='append', index=False)\n",
    "dim_geography.to_sql('dim_geography', engine, if_exists='append', index=False)\n",
    "dim_originating_lender.to_sql('dim_originating_lender', engine, if_exists='append', index=False)\n",
    "dim_borrower.to_sql('dim_borrower', engine, if_exists='append', index=False)\n",
    "dim_servicing_lender.to_sql('dim_servicing_lender', engine, if_exists='append', index=False)\n",
    "dim_loan_status.to_sql('dim_loan_status', engine, if_exists='append', index=False)\n",
    "dim_business_type.to_sql('dim_business_type', engine, if_exists='append', index=False)\n",
    "dim_processing_method.to_sql('dim_processing_method', engine, if_exists='append', index=False)\n",
    "dim_term.to_sql('dim_term', engine, if_exists='append', index=False)\n",
    "dim_business_age.to_sql('dim_business_age', engine, if_exists='append', index=False)\n",
    "date_dimension.to_sql('date_dimension', engine, if_exists='append', index=False)\n",
    "\n",
    "fact_ppp.to_sql('fact_ppp', engine, if_exists='append', index=False)\n",
    "facts_gdp.to_sql('facts_gdp', engine, if_exists='append', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
